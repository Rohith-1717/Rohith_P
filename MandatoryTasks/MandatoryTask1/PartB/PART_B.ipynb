{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7065174,"sourceType":"datasetVersion","datasetId":4068004}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom tokenizers import Tokenizer, models, trainers, pre_tokenizers, processors\n\ndf = pd.read_csv(\"/kaggle/input/high-quality-multilingual-translation-data/en-fr_train.csv\")\ndf['translation'] = df['translation'].apply(eval)\nen_sentences = df['translation'].apply(lambda x: x['en']).dropna().astype(str).tolist()\nfr_sentences = df['translation'].apply(lambda x: x['fr']).dropna().astype(str).tolist()\n\nwith open(\"en.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(en_sentences))\nwith open(\"fr.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(fr_sentences))\n\ndef train_tokenizer(file, name):\n    tokenizer = Tokenizer(models.BPE())\n    tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n    trainer = trainers.BpeTrainer(vocab_size=8000, special_tokens=[\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"])\n    tokenizer.train([file], trainer)\n    tokenizer.post_processor = processors.TemplateProcessing(\n        single=\"<s> $A </s>\",\n        special_tokens=[(\"<s>\", tokenizer.token_to_id(\"<s>\")), (\"</s>\", tokenizer.token_to_id(\"</s>\"))]\n    )\n    tokenizer.save(f\"{name}_tokenizer.json\")\n    return tokenizer\n\nen_tok = train_tokenizer(\"en.txt\", \"en\")\nfr_tok = train_tokenizer(\"fr.txt\", \"fr\")\n\nclass TranslationDataset(Dataset):\n    def __init__(self, src_texts, tgt_texts, src_tok, tgt_tok, max_len=64):\n        self.src = src_texts\n        self.tgt = tgt_texts\n        self.src_tok = src_tok\n        self.tgt_tok = tgt_tok\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.src)\n\n    def __getitem__(self, idx):\n        src_ids = self.src_tok.encode(self.src[idx]).ids[:self.max_len]\n        tgt_ids = self.tgt_tok.encode(self.tgt[idx]).ids[:self.max_len]\n        src_ids += [self.src_tok.token_to_id(\"<pad>\")] * (self.max_len - len(src_ids))\n        tgt_ids += [self.tgt_tok.token_to_id(\"<pad>\")] * (self.max_len - len(tgt_ids))\n        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n\ndataset = TranslationDataset(en_sentences, fr_sentences, en_tok, fr_tok)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nclass TransformerModel(nn.Module):\n    def __init__(self, src_vocab, tgt_vocab, d_model=256, nhead=4, num_layers=3, dropout=0.1):\n        super().__init__()\n        self.src_embed = nn.Embedding(src_vocab, d_model)\n        self.tgt_embed = nn.Embedding(tgt_vocab, d_model)\n        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_layers, num_decoder_layers=num_layers, dropout=dropout)\n        self.fc_out = nn.Linear(d_model, tgt_vocab)\n\n    def forward(self, src, tgt):\n        src = self.src_embed(src).permute(1, 0, 2)\n        tgt = self.tgt_embed(tgt).permute(1, 0, 2)\n        output = self.transformer(src, tgt)\n        return self.fc_out(output).permute(1, 0, 2)\n\nmodel = TransformerModel(src_vocab=en_tok.get_vocab_size(), tgt_vocab=fr_tok.get_vocab_size()).cuda()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nloss_fn = nn.CrossEntropyLoss(ignore_index=en_tok.token_to_id(\"<pad>\"), label_smoothing=0.1)\n\nfor epoch in range(5):\n    model.train()\n    total_loss = 0\n    for src, tgt in loader:\n        src, tgt = src.cuda(), tgt.cuda()\n        tgt_input = tgt[:, :-1]\n        tgt_output = tgt[:, 1:]\n        logits = model(src, tgt_input)\n        loss = loss_fn(logits.reshape(-1, logits.size(-1)), tgt_output.reshape(-1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1} completed. Loss: {total_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"/kaggle/working/transformer_en_fr.pth\")\n\ndef translate(sentence, max_len=64):\n    model.eval()\n    src_ids = en_tok.encode(sentence).ids[:max_len]\n    src_ids += [en_tok.token_to_id(\"<pad>\")] * (max_len - len(src_ids))\n    src_tensor = torch.tensor(src_ids).unsqueeze(0).cuda()\n\n    tgt_start = torch.tensor([fr_tok.token_to_id(\"<s>\")]).unsqueeze(0).cuda()\n    translated = tgt_start\n\n    for _ in range(max_len - 1):\n        output = model(src_tensor, translated)\n        logits = output[:, -1, :]\n        probs = torch.softmax(logits, dim=-1)\n        next_token = torch.multinomial(probs, num_samples=1)\n        translated = torch.cat([translated, next_token], dim=1)\n        if next_token.item() == fr_tok.token_to_id(\"</s>\"):\n            break\n\n    return fr_tok.decode(translated.squeeze().tolist(), skip_special_tokens=True)\n\nprint(translate(\"Hello I am french and I like baguettes\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-20T10:39:40.120813Z","iopub.execute_input":"2025-10-20T10:39:40.121560Z","iopub.status.idle":"2025-10-20T11:00:56.059769Z","shell.execute_reply.started":"2025-10-20T10:39:40.121536Z","shell.execute_reply":"2025-10-20T11:00:56.059151Z"}},"outputs":[{"name":"stdout","text":"\n\n\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 completed. Loss: 22117.7016\nEpoch 2 completed. Loss: 18716.6067\nEpoch 3 completed. Loss: 17081.8680\nEpoch 4 completed. Loss: 16006.9929\nEpoch 5 completed. Loss: 15225.5646\nchances ..., m irré m a questions m m m … oix m m m m m m m m m vir m m m m m m m m m m m m m m m m m m m m m m m m h m m m m m m m m m m m m m m m m\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"/kaggle/input/high-quality-multilingual-translation-data/en-fr_train.csv\")\nprint(df.columns)\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T10:14:08.481785Z","iopub.execute_input":"2025-10-20T10:14:08.482324Z","iopub.status.idle":"2025-10-20T10:14:08.965650Z","shell.execute_reply.started":"2025-10-20T10:14:08.482302Z","shell.execute_reply":"2025-10-20T10:14:08.965027Z"}},"outputs":[{"name":"stdout","text":"Index(['id', 'translation'], dtype='object')\n   id                                        translation\n0   0  {'en': 'The Wanderer', 'fr': 'Le grand Meaulnes'}\n1   1   {'en': 'Alain-Fournier', 'fr': 'Alain-Fournier'}\n2   2      {'en': 'First Part', 'fr': 'PREMIÈRE PARTIE'}\n3   3              {'en': 'I', 'fr': 'CHAPITRE PREMIER'}\n4   4     {'en': 'THE BOARDER', 'fr': 'LE PENSIONNAIRE'}\n","output_type":"stream"}],"execution_count":8}]}