{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade gensim\n!pip install smart_open==5.2.1\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-24T14:17:35.867900Z","iopub.execute_input":"2025-10-24T14:17:35.868143Z","iopub.status.idle":"2025-10-24T14:17:45.845834Z","shell.execute_reply.started":"2025-10-24T14:17:35.868122Z","shell.execute_reply":"2025-10-24T14:17:45.844850Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\nCollecting gensim\n  Downloading gensim-4.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\nRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\nRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.15.3)\nRequirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0.post1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.5->gensim) (2.4.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open>=1.8.1->gensim) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.5->gensim) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.5->gensim) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.5->gensim) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.5->gensim) (2024.2.0)\nDownloading gensim-4.4.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/27.8 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: gensim\n  Attempting uninstall: gensim\n    Found existing installation: gensim 4.3.3\n    Uninstalling gensim-4.3.3:\n      Successfully uninstalled gensim-4.3.3\nSuccessfully installed gensim-4.4.0\nCollecting smart_open==5.2.1\n  Downloading smart_open-5.2.1-py3-none-any.whl.metadata (22 kB)\nDownloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: smart_open\n  Attempting uninstall: smart_open\n    Found existing installation: smart_open 7.3.0.post1\n    Uninstalling smart_open-7.3.0.post1:\n      Successfully uninstalled smart_open-7.3.0.post1\nSuccessfully installed smart_open-5.2.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset\nimport re\nfrom nltk.tokenize import word_tokenize\nfrom gensim.models import Word2Vec, FastText\nfrom gensim.models.callbacks import CallbackAny2Vec\nimport sys, time\nfrom csv import writer\n\nclass Progress(CallbackAny2Vec):\n    def __init__(self, name, total):\n        self.name = name\n        self.total = total\n        self.epoch = 0\n        self.start = time.time()\n    def on_epoch_begin(self, model):\n        self.epoch += 1\n        print(f\"\\n{self.name} → Epoch {self.epoch}/{self.total} started...\")\n        self.epoch_time = time.time()\n    def on_epoch_end(self, model):\n        e = time.time() - self.epoch_time\n        t = time.time() - self.start\n        sys.stdout.write(f\"\\r{self.name} → Epoch {self.epoch}/{self.total} completed ({e:.1f}s, total {t:.1f}s)\")\n        sys.stdout.flush()\n    def on_train_end(self, model):\n        print(f\"\\n{self.name} training complete!\\n\")\n\ndata = load_dataset(\"lucadiliello/newsqa\")\ndocs = []\nfor part in ['train', 'validation']:\n    for item in data[part]:\n        docs.append(str(item['context']))\n        docs.append(str(item['question']))\n        for ans in item['answers']:\n            if isinstance(ans, list):\n                for a in ans:\n                    docs.append(str(a))\n            else:\n                docs.append(str(ans))\n\ndef clean(txt):\n    txt = txt.lower()\n    txt = re.sub(r'[^a-z0-9\\s]', '', txt)\n    return txt\n\ndocs = [clean(t) for t in docs]\ntokens = [word_tokenize(t) for t in docs]\n\nepochs = 5\nprint(\"\\nWord2Vec traing is starting: \")\nw2v = Word2Vec(sentences=tokens, vector_size=150, window=4, min_count=2, workers=4, sg=1, epochs=epochs, callbacks=[Progress(\"Word2Vec\", epochs)])\nwith open(\"w2v_embeddings.csv\", \"w\", newline=\"\") as f:\n    w = writer(f)\n    for i, word in enumerate(w2v.wv.index_to_key):\n        w.writerow([word]+w2v.wv[word].tolist())\n        if i % max(1, len(w2v.wv)//100) == 0:\n            sys.stdout.write(f\"\\rWord2Vec saving progress: {int(i/len(w2v.wv)*100)}%\")\n            sys.stdout.flush()\n    print(\"\\rWord2Vec saved\")\n\nprint(\"\\nFastText is Training\")\nft = FastText(sentences=tokens, vector_size=120, window=6, min_count=1, workers=4, epochs=epochs, callbacks=[Progress(\"FastText\", epochs)])\nwith open(\"fasttext_embeddings.csv\", \"w\", newline=\"\") as f:\n    w = writer(f)\n    for i, word in enumerate(ft.wv.index_to_key):\n        w.writerow([word]+ft.wv[word].tolist())\n        if i % max(1, len(ft.wv)//100) == 0:\n            sys.stdout.write(f\"\\rFastText saving progress: {int(i/len(ft.wv)*100)}%\")\n            sys.stdout.flush()\n    print(\"/nsaving fasttext\")\n\nprint(\"\\nEVerything is saved\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T14:18:02.169279Z","iopub.execute_input":"2025-10-24T14:18:02.169582Z","iopub.status.idle":"2025-10-24T14:45:39.916278Z","shell.execute_reply.started":"2025-10-24T14:18:02.169557Z","shell.execute_reply":"2025-10-24T14:45:39.915526Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/681 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afed75a9078b4e3fab60fdd2dddf70c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-ec54fbe500fc3b(…):   0%|          | 0.00/29.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b989e5a577e146cd8b65f82006f7a4d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001-3cf888b12(…):   0%|          | 0.00/1.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97219a1f6c2540c1bf62615ea88a3304"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/74160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27da0e018bd4416699f311f08dcb1f2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4212 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a2368a8479e4e64840bf93d245891c1"}},"metadata":{}},{"name":"stdout","text":"\nWord2Vec traing is starting: \n\nWord2Vec → Epoch 1/5 started...\nWord2Vec → Epoch 1/5 completed (107.8s, total 114.3s)\nWord2Vec → Epoch 2/5 started...\nWord2Vec → Epoch 2/5 completed (107.1s, total 221.4s)\nWord2Vec → Epoch 3/5 started...\nWord2Vec → Epoch 3/5 completed (113.5s, total 334.9s)\nWord2Vec → Epoch 4/5 started...\nWord2Vec → Epoch 4/5 completed (105.5s, total 440.3s)\nWord2Vec → Epoch 5/5 started...\nWord2Vec → Epoch 5/5 completed (106.2s, total 546.5s)\nWord2Vec training complete!\n\nWord2Vec savedg progress: 99%\n\nFastText is Training\n\nFastText → Epoch 1/5 started...\nFastText → Epoch 1/5 completed (174.2s, total 186.2s)\nFastText → Epoch 2/5 started...\nFastText → Epoch 2/5 completed (173.1s, total 359.3s)\nFastText → Epoch 3/5 started...\nFastText → Epoch 3/5 completed (176.3s, total 535.6s)\nFastText → Epoch 4/5 started...\nFastText → Epoch 4/5 completed (178.2s, total 713.9s)\nFastText → Epoch 5/5 started...\nFastText → Epoch 5/5 completed (175.9s, total 889.8s)\nFastText training complete!\n\nFastText saving progress: 99%/nsaving fasttext\n\nEVerything is saved\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"words_to_test = [\"obama\",\"have\",\"dihh\", \"damn\",\"thats\",\"crazy\"]\n\nprint(\"Word2Vec testing:\")\nfor w in words_to_test:\n    if w in w2v.wv:\n        sim = w2v.wv.most_similar(w, topn=5)\n        print(f\"\\nTop words similar to '{w}':\")\n        for s, score in sim:\n            print(f\"{s} → {score:.3f}\")\n    else:\n        print(f\"{w} not in Word2Vec vocab\")\n\nprint(\"\\nFastText testing:\")\nfor w in words_to_test:\n    if w in ft.wv:\n        sim = ft.wv.most_similar(w, topn=5)\n        print(f\"\\nTop words similar to '{w}':\")\n        for s, score in sim:\n            print(f\"{s} → {score:.3f}\")\n    else:\n        print(f\"{w} not in FastText vocab\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T14:45:49.156906Z","iopub.execute_input":"2025-10-24T14:45:49.157446Z","iopub.status.idle":"2025-10-24T14:45:49.283125Z","shell.execute_reply.started":"2025-10-24T14:45:49.157424Z","shell.execute_reply":"2025-10-24T14:45:49.282300Z"}},"outputs":[{"name":"stdout","text":"Word2Vec testing:\n\nTop words similar to 'obama':\nbarack → 0.862\nobamas → 0.777\npresidentelect → 0.730\nmccain → 0.712\nclinton → 0.706\n\nTop words similar to 'have':\nhad → 0.752\nhas → 0.681\nhavent → 0.646\nbe → 0.589\ntheyve → 0.576\ndihh not in Word2Vec vocab\n\nTop words similar to 'damn':\npeytons → 0.627\nmenopausal → 0.539\nrepressors → 0.537\nabbreviate → 0.533\nkook → 0.529\n\nTop words similar to 'thats':\noveranxious → 0.657\nsupergreat → 0.646\ncategorizes → 0.645\ntasters → 0.635\nunsporting → 0.631\n\nTop words similar to 'crazy':\nextrovert → 0.617\nmotson → 0.563\npawing → 0.562\ngeeked → 0.559\ncheekiness → 0.547\n\nFastText testing:\n\nTop words similar to 'obama':\nobamao → 0.969\nclintonobama → 0.890\nobamaclinton → 0.882\nobamabiden → 0.877\nobamathon → 0.863\n\nTop words similar to 'have':\n16have → 0.915\nhav → 0.878\nhavel → 0.869\nhavent → 0.811\nshave → 0.799\n\nTop words similar to 'dihh':\ndijk → 0.967\ndiy → 0.958\ndikgacoi → 0.880\ndix → 0.829\ndiazs → 0.790\n\nTop words similar to 'damn':\ndam → 0.756\ndamme → 0.756\ndamnit → 0.746\ndaokui → 0.699\ndamnily → 0.697\n\nTop words similar to 'thats':\nghats → 0.745\nbroadlythats → 0.739\nkalathats → 0.728\nthatsfitcom → 0.716\nnihats → 0.700\n\nTop words similar to 'crazy':\ncraze → 0.677\nguitarcrazy → 0.608\ncrap → 0.608\nkrazy → 0.607\ncraggy → 0.597\n","output_type":"stream"}],"execution_count":3}]}