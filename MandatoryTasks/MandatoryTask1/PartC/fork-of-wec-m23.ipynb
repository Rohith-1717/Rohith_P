{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install datasets transformers\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:57:03.088252Z","iopub.execute_input":"2025-10-24T13:57:03.088489Z","iopub.status.idle":"2025-10-24T13:57:06.557324Z","shell.execute_reply.started":"2025-10-24T13:57:03.088469Z","shell.execute_reply":"2025-10-24T13:57:06.556415Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.19.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.5)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\n\nds = load_dataset(\"lucadiliello/newsqa\")\nprint({split: len(ds[split]) for split in ds.keys()})\n\nfor split in ds.keys():\n    print(\"Columns:\", ds[split].column_names)\n    \nsample = ds[\"train\"][0]\nprint(\"Example data: \")\nfor k, v in sample.items():\n    if isinstance(v, str):\n        print(f\"{k}: {v[:200]}\")\n    else:\n        print(f\"{k}: {v}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:57:09.016691Z","iopub.execute_input":"2025-10-24T13:57:09.017299Z","iopub.status.idle":"2025-10-24T13:57:13.660065Z","shell.execute_reply.started":"2025-10-24T13:57:09.017267Z","shell.execute_reply":"2025-10-24T13:57:13.659468Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/681 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45cd4c0126bd42d6ba3c17e2e223ea53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-ec54fbe500fc3b(…):   0%|          | 0.00/29.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"488512c0a04f4773917606c9379bdad0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001-3cf888b12(…):   0%|          | 0.00/1.63M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e749ac9e6024e0281069bbe49464ef5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/74160 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bcb5ff6a0d8439c91c40c4a470d9d88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/4212 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9aafdf6d5add411ca4eda346537541be"}},"metadata":{}},{"name":"stdout","text":"{'train': 74160, 'validation': 4212}\nColumns: ['context', 'question', 'answers', 'key', 'labels']\nColumns: ['context', 'question', 'answers', 'key', 'labels']\nExample data: \ncontext: NEW DELHI, India (CNN) -- A high court in northern India on Friday acquitted a wealthy businessman facing the death sentence for the killing of a teen in a case dubbed \"the house of horrors.\"\n\n\n\nMonin\nquestion: What was the amount of children murdered?\nanswers: ['19']\nkey: da0e6b66e04d439fa1ba23c32de07e50\nlabels: [{'end': [295], 'start': [294]}]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass BiLSTMQA(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=128, layers=2, drop=0.2):\n        super(BiLSTMQA, self).__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=layers, bidirectional=True, batch_first=True, dropout=drop)\n        self.drop = nn.Dropout(drop)\n        self.start_linear = nn.Linear(hidden_dim*2, 1)\n        self.end_linear = nn.Linear(hidden_dim*2, 1)\n\n    def forward(self, tokens, mask):\n        x = self.embed(tokens)\n        x, _ = self.lstm(x)\n        x = self.drop(x)\n        start = self.start_linear(x).squeeze(-1)\n        end = self.end_linear(x).squeeze(-1)\n        start = start.masked_fill(mask==0, -1e9)\n        end = end.masked_fill(mask==0, -1e9)\n        return start, end\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T13:57:17.265484Z","iopub.execute_input":"2025-10-24T13:57:17.265904Z","iopub.status.idle":"2025-10-24T13:57:21.137985Z","shell.execute_reply.started":"2025-10-24T13:57:17.265883Z","shell.execute_reply":"2025-10-24T13:57:21.137208Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nfrom datasets import load_dataset\n\ndata = load_dataset(\"lucadiliello/newsqa\")\ntok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\ndef prep_example(item, max_len=128):\n    enc = tok(\n        item['question'],\n        item['context'],\n        truncation=True,\n        padding='max_length',\n        max_length=max_len,\n        return_offsets_mapping=True\n    )\n    offs = enc.pop(\"offset_mapping\")\n    schar = item['labels'][0]['start'][0]\n    echar = item['labels'][0]['end'][0]\n    enc[\"ids\"] = enc.pop(\"input_ids\")\n    enc[\"mask\"] = enc.pop(\"attention_mask\")\n    enc[\"stpos\"] = 0\n    enc[\"enpos\"] = 0\n    for i, (s, e) in enumerate(offs):\n        if s <= schar < e:\n            enc[\"stpos\"] = i\n        if s < echar <= e:\n            enc[\"enpos\"] = i\n    return enc\n\nclass QAData(Dataset):\n    def __init__(self, examples):\n        self.examples = examples\n\n    def __len__(self):\n        return len(self.examples)\n\n    def __getitem__(self, idx):\n        ex = self.examples[idx]\n        return {\n            'ids': torch.tensor(ex['ids']),\n            'mask': torch.tensor(ex['mask']),\n            'stpos': torch.tensor(ex['stpos']),\n            'enpos': torch.tensor(ex['enpos'])\n        }\n\ntrain_subset = data['train'].select(range(2000))\ntrain_tok = [prep_example(x) for x in train_subset]\n\nTrainD = QAData(train_tok)\nTL = DataLoader(TrainD, batch_size=8, shuffle=True)\n\n\nvsize = tok.vocab_size\nmodel = BiLSTMQA(vsize).cuda()\nCEL = nn.CrossEntropyLoss()\nADAM = optim.Adam(model.parameters(), lr=1e-3)\n\nfor ep in range(20):\n    total_loss = 0\n    for batch in TL:\n        ids = batch['ids'].cuda()\n        mask = batch['mask'].cuda()\n        stpos = batch['stpos'].cuda()\n        enpos = batch['enpos'].cuda()\n\n        ADAM.zero_grad()\n        st_logits, en_logits = model(ids, mask)\n        loss_st = CEL(st_logits, stpos)\n        loss_en = CEL(en_logits, enpos)\n        loss = (loss_st + loss_en) / 2\n        loss.backward()\n        ADAM.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {ep+1}, Loss: {total_loss/len(TL):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T14:04:15.071984Z","iopub.execute_input":"2025-10-24T14:04:15.072412Z","iopub.status.idle":"2025-10-24T14:04:56.501867Z","shell.execute_reply.started":"2025-10-24T14:04:15.072382Z","shell.execute_reply":"2025-10-24T14:04:56.501066Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 3.3584\nEpoch 2, Loss: 2.7257\nEpoch 3, Loss: 2.2923\nEpoch 4, Loss: 1.9587\nEpoch 5, Loss: 1.6958\nEpoch 6, Loss: 1.4459\nEpoch 7, Loss: 1.2496\nEpoch 8, Loss: 1.1098\nEpoch 9, Loss: 1.0153\nEpoch 10, Loss: 0.9453\nEpoch 11, Loss: 0.8931\nEpoch 12, Loss: 0.8587\nEpoch 13, Loss: 0.8192\nEpoch 14, Loss: 0.8031\nEpoch 15, Loss: 0.7798\nEpoch 16, Loss: 0.7702\nEpoch 17, Loss: 0.7430\nEpoch 18, Loss: 0.7118\nEpoch 19, Loss: 0.6956\nEpoch 20, Loss: 0.6875\n","output_type":"stream"}],"execution_count":9}]}